{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import csv\n",
    "from scipy.stats import kurtosis, skew\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = np.ones((5,5),np.uint8)\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil label gambar berdasar foldernya\n",
    "labels = [os.path.dirname(file).split('\\\\')[1] for file in glob.glob(\"./downloads/*/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = [[os.path.dirname(file).split('\\\\')[1], os.path.basename(file)] for file in glob.glob(\"./downloads/*/*\")]\n",
    "# new = [x for x in file_name]\n",
    "\n",
    "# file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image\n",
    "\n",
    "images = [cv2.imread(file) for file in glob.glob(\"./downloads/*/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi ekstrak fitur color moment\n",
    "def get_color_feature(img):\n",
    "    color_feat = []\n",
    "    for x in img:\n",
    "        temp = [np.mean(x), np.std(x), skew(skew(x)), kurtosis(kurtosis(x))]\n",
    "        for t in temp:\n",
    "            color_feat.append(t)\n",
    "\n",
    "    return color_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_hist_val(img):\n",
    "    chan_hist = []\n",
    "    for chan in img:\n",
    "        hist = cv2.calcHist([chan],[0],None,[256],[0,256])\n",
    "        norm_hist = cv2.normalize(hist, hist).flatten()\n",
    "        res = [sum(norm_hist), np.mean(norm_hist), np.std(norm_hist)]\n",
    "        for r in res:\n",
    "            chan_hist.append(r)\n",
    "            \n",
    "    return chan_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi kalkulasi matriks glcm dengan sudut gambar 0, 45, 90, 135 derajat\n",
    "# agls = , np.pi/4, np.pi/2, 3*np.pi/4\n",
    "def calc_glcm_all_agls(img, label, props, dists=[5], agls=[0, np.pi/4, np.pi/2, 3*np.pi/4], lvl=256, sym=True, norm=True):\n",
    "    \n",
    "    glcm = greycomatrix(img, \n",
    "                        distances=dists, \n",
    "                        angles=agls, \n",
    "                        levels=lvl,\n",
    "                        symmetric=sym, \n",
    "                        normed=norm)\n",
    "    feature = []\n",
    "    glcm_props = [propery for name in props for propery in greycoprops(glcm, name)[0]]\n",
    "    for item in glcm_props:\n",
    "            feature.append(item)\n",
    "    feature.append(label) \n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi get glcm\n",
    "\n",
    "def glcm_features(img, label=\"no label\"):\n",
    "    properties = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    glcm_feat = calc_glcm_all_agls(gray, label, props=properties)\n",
    "        \n",
    "    return glcm_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_equal(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # equalize the histogram of the Y channel\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\n",
    "    # convert the YUV image back to RGB format\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi resize citra\n",
    "def resize_image(img):\n",
    "    resized = cv2.resize(img, (500, 500))\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ekstraksi fitur dari citra\n",
    "def extract_feature(images, labels):\n",
    "    imgs_feat = []\n",
    "    # i = 0\n",
    "    for image, label in zip(images, labels):\n",
    "        imgs = resize_image(image)\n",
    "        img = hist_equal(imgs)\n",
    "        glcm_feature = glcm_features(img, label)\n",
    "\n",
    "        split_chans = cv2.split(img)\n",
    "        color_feature = get_color_feature(split_chans)\n",
    "        color_hist = get_color_hist_val(split_chans)\n",
    "        imgs_feat.append(color_hist + color_feature + glcm_feature)\n",
    "    #     i = i + 1\n",
    "    \n",
    "    return imgs_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_feat = extract_feature(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_dataset = pickle.dumps(img_train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_feature = pickle.loads(training_image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_feat = len(training_image_feature[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# minmax scaler\n",
    "# scaler.fit(rounded_scale)\n",
    "train_feat_only = [[x for x in y[:len_feat-1]] for y in training_image_feature]\n",
    "scaled_feat = scaler.fit_transform(train_feat_only)\n",
    "# pembulatan nilai feature\n",
    "rounded_scale = [[round(x, 5) for x in y] for y in scaled_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(scaled_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering k-means dengan jumlah cluster 50 dan iterasi maksimum 200\n",
    "kmeans = KMeans(n_clusters=n, max_iter=200).fit(rounded_scale)\n",
    "\n",
    "y = kmeans.predict(rounded_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1499"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menyatukan feature dengan label yang sesuai\n",
    "\n",
    "with_nama_makanan = []\n",
    "for i in range(len(rounded_scale)):\n",
    "    label = [labels[i]]\n",
    "    with_nama_makanan.append(rounded_scale[i] + label)\n",
    "    \n",
    "len(with_nama_makanan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menyatukan citra dengan cluster hasil clustering k-means\n",
    "with_label = list(zip(with_nama_makanan, y))\n",
    "\n",
    "# mengurutkan hasil clustering\n",
    "temp = sorted(with_label, key=lambda x: x[1])\n",
    "\n",
    "# inisialisasi variabel baru untuk menyimpan data berdasar cluster\n",
    "new = []\n",
    "\n",
    "# pemisahan data untuk setiap cluster\n",
    "for i in range(0, n):\n",
    "    temps = []\n",
    "    for x in temp:\n",
    "        if i == x[1]:\n",
    "            temps.append(x[0])\n",
    "    new.append(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid dari hasil k-means clustering\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi euclidean distance\n",
    "def euclidean_distance(input_data, dataset):\n",
    "    distances = []\n",
    "    for data in dataset:\n",
    "        dist = math.sqrt(sum([(a - b) ** 2 for a, b in zip(input_data, data)]))\n",
    "        distances.append(dist)\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi klasifikasi knn\n",
    "def knn(k, datatest, datatrain, nearest_cluster):\n",
    "    data = datatrain[nearest_cluster]\n",
    "    \n",
    "    data_without_label = [x[:len_feat-1] for x in data]\n",
    "    label_only = [x[-1] for x in data]\n",
    "    \n",
    "    distance = euclidean_distance(datatest, data_without_label)\n",
    "    zipped = list(zip(distance, label_only))\n",
    "    temp = sorted(zipped, key=lambda x: x[0])\n",
    "    \n",
    "    nearest_neighbor = temp[:k]\n",
    "    \n",
    "    most_label = [x[1] for x in nearest_neighbor]\n",
    "    \n",
    "    return Counter(most_label).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_test(data_train, data_test):\n",
    "    data_train.append(data_test)\n",
    "    scaled = scaler.fit_transform(data_train)\n",
    "    \n",
    "    return scaled[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = [os.path.dirname(file).split('\\\\')[1] for file in glob.glob(\"./downloads/*/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.92661774516344\n",
      "Time:  104.62105979999978\n"
     ]
    }
   ],
   "source": [
    "# image untuk testing\n",
    "# test_images = [cv2.imread(file) for file in glob.glob(\"./downloads/*/*\")]\n",
    "start = timeit.default_timer()\n",
    "file_name = [os.path.dirname(file).split('\\\\')[1] for file in glob.glob(\"./downloads/*/*\")]\n",
    "\n",
    "the_ks = [3, 5, 15, 25, 50]\n",
    "the_accs = []\n",
    "\n",
    "\n",
    "pred_labels = []\n",
    "for x in training_image_feature:\n",
    "    test_feat_only = x[:len_feat-1]\n",
    "    normed = normalize_test(train_feat_only, test_feat_only)\n",
    "    cluster_distance_test = euclidean_distance(normed, centroids)\n",
    "    nearest_cluster_test = cluster_distance_test.index(min(cluster_distance_test))\n",
    "    # #     print(nearest_cluster_test)\n",
    "    predicted_label = knn(3, normed, new, nearest_cluster_test)\n",
    "    pred_labels.append(predicted_label)\n",
    "\n",
    "i = 0\n",
    "for act, pred in zip(file_name, pred_labels):\n",
    "        if act.lower() == pred.lower():\n",
    "            i = i+1\n",
    "\n",
    "acc = i/len(pred_labels) * 100\n",
    "    \n",
    "print(acc)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [cv2.imread(file) for file in glob.glob(\"./sampel gambar/*\")]\n",
    "feature_test = []\n",
    "\n",
    "for x in test_images:\n",
    "    imgs = resize_image(x)\n",
    "    img = hist_equal(imgs)\n",
    "#     img_conv = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "#     blurtest = cv2.GaussianBlur(x,(5,5),0)\n",
    "    split_chans_test = cv2.split(img)\n",
    "#     get_color_hist_val(split_chans_test) + \n",
    "    test_feat = get_color_hist_val(split_chans_test) + get_color_feature(split_chans_test) + glcm_features(img)\n",
    "    feature_test.append(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_image_dataset = pickle.dumps(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_image_features = pickle.loads(testing_image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.666666666666668\n",
      "[('bakso', 'gado gado'), ('bika ambon', 'mie ayam'), ('cucur', 'kentang goreng'), ('gado-gado', 'serabi'), ('getuk', 'bakso'), ('kentang goreng', 'bika ambon'), ('martabak manis', 'martabak manis'), ('mie ayam', 'mie ayam'), ('nasi kuning', 'opor ayam'), ('onde-onde', 'mie ayam'), ('opor ayam', 'opor ayam'), ('pempek', 'cucur'), ('rendang daging', 'nasi kuning'), ('sate', 'getuk'), ('serabi', 'serabi')]\n",
      "time:  1.044618600000831\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "fname = [os.path.basename(file).split('.')[0].lower() for file in glob.glob(\"./sampel gambar/*\")]\n",
    "# c = input()\n",
    "tempus = []\n",
    "for x in testing_image_features:\n",
    "\n",
    "    test_feat_onlys = x[:len_feat-1]\n",
    "    normed = normalize_test(train_feat_only, test_feat_onlys)\n",
    "    cluster_distance_test = euclidean_distance(normed, centroids)\n",
    "    nearest_cluster_test = cluster_distance_test.index(min(cluster_distance_test))\n",
    "        # #     print(nearest_cluster_test)\n",
    "    predicted_label = knn(3, normed, new, nearest_cluster_test)\n",
    "    tempus.append(predicted_label.lower())\n",
    "    \n",
    "temp_count = 0\n",
    "for a, b in list(zip(fname, tempus)):\n",
    "    if a == b:\n",
    "        temp_count += 1\n",
    "        \n",
    "print(temp_count/15 * 100)\n",
    "print(list(zip(fname, tempus)))\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(\"time: \", stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7/15 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('image_feature3.csv', 'w', newline='\\n', encoding='utf8')\n",
    "\n",
    "# with f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(training_image_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
